{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify digits.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/penguinprogramer/Clasify-digits/blob/master/classify_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90X-QAgO3XA9",
        "colab_type": "text"
      },
      "source": [
        "# first firls we have to load  the images\n",
        "------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7DKvd6R4OC9",
        "colab_type": "text"
      },
      "source": [
        "Download images \n",
        "\n",
        "i created this datasel myself by writing a whole load of numbers down on paper. \n",
        "after that i scanned them in usuing a flatbed scanner\n",
        "\n",
        "then i used imagemagick to preprocess the images \n",
        "\n",
        "while it would have been al lit quicker to use a pre-existing dataset such as mnist, i thought it would be fun to create one from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-JR7WQ5O70X",
        "colab": {}
      },
      "source": [
        "!curl -O https://fadedace-gci.web.app/monodigits.zip\n",
        "!unzip monodigits.zip\n",
        "! rm digits/26.png\n",
        "! rm digits/33.png\n",
        "! rm digits/a.png\n",
        "! rm digits/split.rb # here i an removing left over bits that i used when separating up he image and preprocessing them"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRbRF6FF4UeY",
        "colab_type": "text"
      },
      "source": [
        "# Import required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OGNpmn43C0O6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "45e37c17-6fec-4eb9-ddaa-b3701c7893dd"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "import numpy as np\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "\n",
        "import pathlib\n",
        "data_dir = pathlib.Path(\"/content/digits\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8TTo2sieZqV",
        "colab_type": "text"
      },
      "source": [
        "lets get familiar with the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPE3HniL7fug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.png')))\n",
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cUbc5_Qc5nO",
        "colab_type": "code",
        "outputId": "a31320b9-eeea-4fa9-e330-1f907d99f1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(image_count)\n",
        "\n",
        "print(CLASS_NAMES ) #lets briefly check we have a class for each didgit"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2669\n",
            "['5' '1' '7' '9' '2' '4' '3' '0' '6' '8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qokGKYIx8juC",
        "colab_type": "code",
        "outputId": "bcbb6230-4211-4c96-c8bf-60a576d68b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "zero = list(data_dir.glob('0/*'))\n",
        "\n",
        "for image_path in zero[:3]:\n",
        "    display.display(Image.open(str(image_path)))  #lets have a look at a few of our images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeAQAAAAATS5MPAAAAW0lEQVR4nG3NsQ2CABRF0cODgsIR\nLJjDWDiKwzgYozCCCRZogG+Lic0p722KLfBDL+qiKe+usz3E2o5qrmu83INncAuWmPQxHCqjmvdz\n7J9BLdboWtGeNP+XR74MShtJccZ4LQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=1 size=30x30 at 0x7FA70DD60198>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeAQAAAAATS5MPAAAAXElEQVR4nH3OsQ2DQBQE0fnLkdKD\nO6CAk4xcqGN6Q3LCJcA/rQOnyMlkT5owdAH8ywz2kIIPYTrieBFu21u0B2IF/HT9CS9A2lUBKDE6\nYWF3pqBRxohLhYm4OfgCHr4gzFlefQ0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=1 size=30x30 at 0x7FA70DD165F8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeAQAAAAATS5MPAAAATUlEQVR4nI3NoQ2DUAAFwPsvyCa1\nlSxAwgZllI7aERgBgUJBgqI0nxUwZ69U/oH7bIPYJ6WOuhhfwoP6/p2hEZ9DWMQ6U7/PM9peubld\n/1UUjviuz6YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=1 size=30x30 at 0x7FA70DD16630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2XpqweM89n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, \n",
        "                                                                  \n",
        "                                                                  validation_split=0.2\n",
        "                                                                  )\n",
        "BATCH_SIZE = 10\n",
        "IMG_HEIGHT = 30 # the images are 30x30 px\n",
        "IMG_WIDTH = 30\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzaMsSEa9WyK",
        "colab_type": "code",
        "outputId": "e8a0e863-0a13-42f9-b613-17166bd69c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "train_generator = image_generator.flow_from_directory(directory=str(data_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True, #this is important as the model may not generalise well if it learns the order of thetraining data \n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES),\n",
        "\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = image_generator.flow_from_directory(directory=str(data_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES),\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2142 images belonging to 10 classes.\n",
            "Found 527 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkqopn47CTp9",
        "colab_type": "code",
        "outputId": "ff0534d2-55a7-41ee-e99a-7c30ed9fea67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator.image_shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 30, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvmirIgW_iBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "75be3241-ef84-4718-841c-8d2af046f73b"
      },
      "source": [
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "\n",
        "\n",
        " #lets set up the model\n",
        "model =tf.keras.Sequential()\n",
        "model.add(layers.Conv2D(30, (3, 3), activation='relu', input_shape=IMG_SHAPE))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(10)) # since there are 10 output classes\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GVsfUq-M9lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_learning_rate = 0.001\n",
        "model.compile(\n",
        "  loss='mean_squared_error', optimizer='sgd', #this is one of the simplest loss functios and optimisers but it works well enough for our purposes\n",
        "  metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Xp5B7ONB2D",
        "colab_type": "code",
        "outputId": "cd3f4668-2d6f-4d7e-fd5c-2a3ead6a8c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 30)        840       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 30)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 12, 12, 64)        17344     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 55,762\n",
            "Trainable params: 55,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrpaEblDNTCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f839f28-3fdd-4c24-bfe7-5c13fb18cd9b"
      },
      "source": [
        "EPOCHS = 200 # with around 100 epocs i got an accuracy of about 90%\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH ,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=200 // BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.0881Epoch 1/200\n",
            "267/267 [==============================] - 7s 25ms/step - loss: 0.0931 - acc: 0.0882 - val_loss: 0.0903 - val_acc: 0.0800\n",
            "Epoch 2/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.1079Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0897 - acc: 0.1097 - val_loss: 0.0897 - val_acc: 0.1350\n",
            "Epoch 3/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.1741Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0892 - acc: 0.1754 - val_loss: 0.0894 - val_acc: 0.1200\n",
            "Epoch 4/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.1995Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0887 - acc: 0.1995 - val_loss: 0.0888 - val_acc: 0.1200\n",
            "Epoch 5/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.2424Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0881 - acc: 0.2434 - val_loss: 0.0884 - val_acc: 0.2450\n",
            "Epoch 6/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.2702Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0876 - acc: 0.2693 - val_loss: 0.0880 - val_acc: 0.1950\n",
            "Epoch 7/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.2858Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0869 - acc: 0.2849 - val_loss: 0.0874 - val_acc: 0.2850\n",
            "Epoch 8/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.2898Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0864 - acc: 0.2895 - val_loss: 0.0868 - val_acc: 0.2600\n",
            "Epoch 9/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.3067Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0857 - acc: 0.3063 - val_loss: 0.0864 - val_acc: 0.2300\n",
            "Epoch 10/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.3283Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0848 - acc: 0.3276 - val_loss: 0.0854 - val_acc: 0.2600\n",
            "Epoch 11/200\n",
            "261/267 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.3086Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0842 - acc: 0.3077 - val_loss: 0.0846 - val_acc: 0.2500\n",
            "Epoch 12/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.3126Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0833 - acc: 0.3139 - val_loss: 0.0841 - val_acc: 0.3050\n",
            "Epoch 13/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.3326Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0825 - acc: 0.3328 - val_loss: 0.0832 - val_acc: 0.3100\n",
            "Epoch 14/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.3412Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0817 - acc: 0.3414 - val_loss: 0.0825 - val_acc: 0.2700\n",
            "Epoch 15/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.3419Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0812 - acc: 0.3397 - val_loss: 0.0823 - val_acc: 0.3300\n",
            "Epoch 16/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.3442Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0805 - acc: 0.3440 - val_loss: 0.0813 - val_acc: 0.3400\n",
            "Epoch 17/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.3516Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0797 - acc: 0.3527 - val_loss: 0.0809 - val_acc: 0.3150\n",
            "Epoch 18/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.3434Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0793 - acc: 0.3429 - val_loss: 0.0804 - val_acc: 0.4150\n",
            "Epoch 19/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.3745Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0784 - acc: 0.3742 - val_loss: 0.0798 - val_acc: 0.3900\n",
            "Epoch 20/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.3838Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0782 - acc: 0.3843 - val_loss: 0.0796 - val_acc: 0.3000\n",
            "Epoch 21/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.3848Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0773 - acc: 0.3828 - val_loss: 0.0791 - val_acc: 0.3950\n",
            "Epoch 22/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.4129Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0770 - acc: 0.4125 - val_loss: 0.0788 - val_acc: 0.4450\n",
            "Epoch 23/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.3928Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0768 - acc: 0.3929 - val_loss: 0.0783 - val_acc: 0.4500\n",
            "Epoch 24/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.4363Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0759 - acc: 0.4359 - val_loss: 0.0778 - val_acc: 0.4200\n",
            "Epoch 25/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.4358Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0756 - acc: 0.4354 - val_loss: 0.0773 - val_acc: 0.3600\n",
            "Epoch 26/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.4438Epoch 1/200\n",
            "267/267 [==============================] - 3s 11ms/step - loss: 0.0750 - acc: 0.4446 - val_loss: 0.0765 - val_acc: 0.4650\n",
            "Epoch 27/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.4740Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0747 - acc: 0.4745 - val_loss: 0.0763 - val_acc: 0.5450\n",
            "Epoch 28/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.4823Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0741 - acc: 0.4823 - val_loss: 0.0755 - val_acc: 0.5150\n",
            "Epoch 29/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.4882Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0736 - acc: 0.4894 - val_loss: 0.0751 - val_acc: 0.4650\n",
            "Epoch 30/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.4973Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0732 - acc: 0.4970 - val_loss: 0.0743 - val_acc: 0.5750\n",
            "Epoch 31/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.5148Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0727 - acc: 0.5165 - val_loss: 0.0738 - val_acc: 0.5500\n",
            "Epoch 32/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.5429Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0721 - acc: 0.5421 - val_loss: 0.0734 - val_acc: 0.5300\n",
            "Epoch 33/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.5477Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0715 - acc: 0.5470 - val_loss: 0.0729 - val_acc: 0.5750\n",
            "Epoch 34/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.5661Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0709 - acc: 0.5672 - val_loss: 0.0725 - val_acc: 0.5350\n",
            "Epoch 35/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.5533Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0708 - acc: 0.5535 - val_loss: 0.0715 - val_acc: 0.6100\n",
            "Epoch 36/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.5825Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0697 - acc: 0.5830 - val_loss: 0.0719 - val_acc: 0.6200\n",
            "Epoch 37/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.6041Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0694 - acc: 0.6029 - val_loss: 0.0705 - val_acc: 0.6100\n",
            "Epoch 38/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.5992Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0689 - acc: 0.5984 - val_loss: 0.0704 - val_acc: 0.6050\n",
            "Epoch 39/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.6296Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0683 - acc: 0.6304 - val_loss: 0.0697 - val_acc: 0.6550\n",
            "Epoch 40/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.6244Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0680 - acc: 0.6243 - val_loss: 0.0698 - val_acc: 0.6700\n",
            "Epoch 41/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.6548Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0668 - acc: 0.6510 - val_loss: 0.0687 - val_acc: 0.6600\n",
            "Epoch 42/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.6568Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0666 - acc: 0.6551 - val_loss: 0.0684 - val_acc: 0.6500\n",
            "Epoch 43/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.6625Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0658 - acc: 0.6628 - val_loss: 0.0677 - val_acc: 0.6700\n",
            "Epoch 44/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.6748Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0654 - acc: 0.6745 - val_loss: 0.0670 - val_acc: 0.6400\n",
            "Epoch 45/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.6763Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0650 - acc: 0.6748 - val_loss: 0.0662 - val_acc: 0.6850\n",
            "Epoch 46/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.6900Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0639 - acc: 0.6897 - val_loss: 0.0652 - val_acc: 0.6700\n",
            "Epoch 47/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.7017Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0634 - acc: 0.7029 - val_loss: 0.0655 - val_acc: 0.6650\n",
            "Epoch 48/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.7112Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0629 - acc: 0.7104 - val_loss: 0.0648 - val_acc: 0.7050\n",
            "Epoch 49/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.7210Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0623 - acc: 0.7200 - val_loss: 0.0645 - val_acc: 0.6550\n",
            "Epoch 50/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.7285Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0618 - acc: 0.7280 - val_loss: 0.0641 - val_acc: 0.6850\n",
            "Epoch 51/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.7310Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0611 - acc: 0.7303 - val_loss: 0.0626 - val_acc: 0.7000\n",
            "Epoch 52/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.7492Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0601 - acc: 0.7487 - val_loss: 0.0622 - val_acc: 0.6900\n",
            "Epoch 53/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.7403Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0600 - acc: 0.7397 - val_loss: 0.0626 - val_acc: 0.7150\n",
            "Epoch 54/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.7602Epoch 1/200\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.0591 - acc: 0.7600 - val_loss: 0.0612 - val_acc: 0.7050\n",
            "Epoch 55/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.7622Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0585 - acc: 0.7607 - val_loss: 0.0609 - val_acc: 0.6950\n",
            "Epoch 56/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.7673Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0575 - acc: 0.7678 - val_loss: 0.0606 - val_acc: 0.7100\n",
            "Epoch 57/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.7686Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0575 - acc: 0.7679 - val_loss: 0.0593 - val_acc: 0.7400\n",
            "Epoch 58/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.7822Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0566 - acc: 0.7825 - val_loss: 0.0587 - val_acc: 0.7400\n",
            "Epoch 59/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.7949Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0557 - acc: 0.7939 - val_loss: 0.0579 - val_acc: 0.7250\n",
            "Epoch 60/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.7945Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0558 - acc: 0.7923 - val_loss: 0.0588 - val_acc: 0.7200\n",
            "Epoch 61/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.8002Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0542 - acc: 0.8002 - val_loss: 0.0578 - val_acc: 0.7200\n",
            "Epoch 62/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.8074Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0544 - acc: 0.8069 - val_loss: 0.0562 - val_acc: 0.7500\n",
            "Epoch 63/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.8139Epoch 1/200\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.0536 - acc: 0.8122 - val_loss: 0.0564 - val_acc: 0.7500\n",
            "Epoch 64/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.8171Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0530 - acc: 0.8178 - val_loss: 0.0559 - val_acc: 0.7450\n",
            "Epoch 65/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.8269Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0523 - acc: 0.8263 - val_loss: 0.0558 - val_acc: 0.7350\n",
            "Epoch 66/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.8326Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0517 - acc: 0.8343 - val_loss: 0.0539 - val_acc: 0.7800\n",
            "Epoch 67/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.8359Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0513 - acc: 0.8362 - val_loss: 0.0554 - val_acc: 0.7500\n",
            "Epoch 68/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.8424Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0507 - acc: 0.8422 - val_loss: 0.0538 - val_acc: 0.7700\n",
            "Epoch 69/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.8409Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0500 - acc: 0.8400 - val_loss: 0.0531 - val_acc: 0.7650\n",
            "Epoch 70/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.8548Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0499 - acc: 0.8546 - val_loss: 0.0528 - val_acc: 0.8100\n",
            "Epoch 71/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.8558Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0490 - acc: 0.8561 - val_loss: 0.0524 - val_acc: 0.8100\n",
            "Epoch 72/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.8548Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0488 - acc: 0.8539 - val_loss: 0.0526 - val_acc: 0.7350\n",
            "Epoch 73/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.8569Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0484 - acc: 0.8568 - val_loss: 0.0517 - val_acc: 0.8200\n",
            "Epoch 74/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.8721Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0473 - acc: 0.8734 - val_loss: 0.0508 - val_acc: 0.8100\n",
            "Epoch 75/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.8749Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0472 - acc: 0.8753 - val_loss: 0.0505 - val_acc: 0.8200\n",
            "Epoch 76/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.8721Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0466 - acc: 0.8727 - val_loss: 0.0513 - val_acc: 0.8000\n",
            "Epoch 77/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.8752Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0462 - acc: 0.8745 - val_loss: 0.0500 - val_acc: 0.8200\n",
            "Epoch 78/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.8880Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0457 - acc: 0.8881 - val_loss: 0.0495 - val_acc: 0.8150\n",
            "Epoch 79/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.8944Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0447 - acc: 0.8948 - val_loss: 0.0499 - val_acc: 0.8100\n",
            "Epoch 80/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.8826Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0449 - acc: 0.8828 - val_loss: 0.0494 - val_acc: 0.8050\n",
            "Epoch 81/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.8886Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0441 - acc: 0.8888 - val_loss: 0.0475 - val_acc: 0.8650\n",
            "Epoch 82/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9005Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0437 - acc: 0.9008 - val_loss: 0.0473 - val_acc: 0.8550\n",
            "Epoch 83/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9066Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0431 - acc: 0.9065 - val_loss: 0.0475 - val_acc: 0.8350\n",
            "Epoch 84/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9061Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0426 - acc: 0.9057 - val_loss: 0.0462 - val_acc: 0.8750\n",
            "Epoch 85/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9073Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0422 - acc: 0.9068 - val_loss: 0.0468 - val_acc: 0.8350\n",
            "Epoch 86/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9077Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0418 - acc: 0.9077 - val_loss: 0.0469 - val_acc: 0.8500\n",
            "Epoch 87/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9122Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0414 - acc: 0.9121 - val_loss: 0.0455 - val_acc: 0.8550\n",
            "Epoch 88/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9077Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0413 - acc: 0.9068 - val_loss: 0.0449 - val_acc: 0.8500\n",
            "Epoch 89/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9230Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0405 - acc: 0.9235 - val_loss: 0.0447 - val_acc: 0.8750\n",
            "Epoch 90/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9227Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0398 - acc: 0.9230 - val_loss: 0.0441 - val_acc: 0.8600\n",
            "Epoch 91/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9231Epoch 1/200\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.0396 - acc: 0.9234 - val_loss: 0.0442 - val_acc: 0.8600\n",
            "Epoch 92/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9262Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0390 - acc: 0.9265 - val_loss: 0.0427 - val_acc: 0.8800\n",
            "Epoch 93/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9276Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0386 - acc: 0.9275 - val_loss: 0.0433 - val_acc: 0.8900\n",
            "Epoch 94/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9300Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0386 - acc: 0.9307 - val_loss: 0.0425 - val_acc: 0.8850\n",
            "Epoch 95/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9315Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0380 - acc: 0.9314 - val_loss: 0.0426 - val_acc: 0.8700\n",
            "Epoch 96/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9268Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0378 - acc: 0.9264 - val_loss: 0.0424 - val_acc: 0.8850\n",
            "Epoch 97/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9401Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0372 - acc: 0.9403 - val_loss: 0.0431 - val_acc: 0.8750\n",
            "Epoch 98/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9377Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0365 - acc: 0.9378 - val_loss: 0.0417 - val_acc: 0.8750\n",
            "Epoch 99/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9333Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0369 - acc: 0.9331 - val_loss: 0.0418 - val_acc: 0.8650\n",
            "Epoch 100/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9403Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0360 - acc: 0.9406 - val_loss: 0.0420 - val_acc: 0.8700\n",
            "Epoch 101/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9410Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0358 - acc: 0.9418 - val_loss: 0.0408 - val_acc: 0.8900\n",
            "Epoch 102/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9426Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0353 - acc: 0.9424 - val_loss: 0.0418 - val_acc: 0.8750\n",
            "Epoch 103/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9483Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0350 - acc: 0.9482 - val_loss: 0.0407 - val_acc: 0.8650\n",
            "Epoch 104/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9443Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0346 - acc: 0.9442 - val_loss: 0.0398 - val_acc: 0.8950\n",
            "Epoch 105/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9424Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0347 - acc: 0.9423 - val_loss: 0.0398 - val_acc: 0.8850\n",
            "Epoch 106/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9517Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0338 - acc: 0.9515 - val_loss: 0.0392 - val_acc: 0.8750\n",
            "Epoch 107/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9503Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0337 - acc: 0.9503 - val_loss: 0.0397 - val_acc: 0.9000\n",
            "Epoch 108/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9491Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0336 - acc: 0.9485 - val_loss: 0.0396 - val_acc: 0.8850\n",
            "Epoch 109/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9520Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0332 - acc: 0.9518 - val_loss: 0.0392 - val_acc: 0.8850\n",
            "Epoch 110/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9521Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0328 - acc: 0.9519 - val_loss: 0.0382 - val_acc: 0.8650\n",
            "Epoch 111/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9546Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0326 - acc: 0.9549 - val_loss: 0.0374 - val_acc: 0.8950\n",
            "Epoch 112/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9567Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0325 - acc: 0.9564 - val_loss: 0.0380 - val_acc: 0.9000\n",
            "Epoch 113/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9580Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0319 - acc: 0.9576 - val_loss: 0.0373 - val_acc: 0.8800\n",
            "Epoch 114/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9586Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0317 - acc: 0.9583 - val_loss: 0.0371 - val_acc: 0.9050\n",
            "Epoch 115/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9579Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0313 - acc: 0.9583 - val_loss: 0.0375 - val_acc: 0.8900\n",
            "Epoch 116/200\n",
            "261/267 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9588Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0310 - acc: 0.9578 - val_loss: 0.0393 - val_acc: 0.8950\n",
            "Epoch 117/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9633Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0309 - acc: 0.9631 - val_loss: 0.0374 - val_acc: 0.8950\n",
            "Epoch 118/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9615Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0305 - acc: 0.9614 - val_loss: 0.0374 - val_acc: 0.8900\n",
            "Epoch 119/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9569Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0306 - acc: 0.9574 - val_loss: 0.0372 - val_acc: 0.9050\n",
            "Epoch 120/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9600Epoch 1/200\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.0300 - acc: 0.9602 - val_loss: 0.0363 - val_acc: 0.9050\n",
            "Epoch 121/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9638Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0299 - acc: 0.9636 - val_loss: 0.0356 - val_acc: 0.8900\n",
            "Epoch 122/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9662Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0294 - acc: 0.9661 - val_loss: 0.0367 - val_acc: 0.8750\n",
            "Epoch 123/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9631Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0294 - acc: 0.9632 - val_loss: 0.0352 - val_acc: 0.8900\n",
            "Epoch 124/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9662Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0293 - acc: 0.9658 - val_loss: 0.0352 - val_acc: 0.9000\n",
            "Epoch 125/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9669Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0288 - acc: 0.9673 - val_loss: 0.0352 - val_acc: 0.8950\n",
            "Epoch 126/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9648Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0291 - acc: 0.9650 - val_loss: 0.0349 - val_acc: 0.9000\n",
            "Epoch 127/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9716Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0281 - acc: 0.9719 - val_loss: 0.0349 - val_acc: 0.9050\n",
            "Epoch 128/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9697Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0282 - acc: 0.9687 - val_loss: 0.0345 - val_acc: 0.9050\n",
            "Epoch 129/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9696Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0279 - acc: 0.9699 - val_loss: 0.0338 - val_acc: 0.8900\n",
            "Epoch 130/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9712Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0277 - acc: 0.9711 - val_loss: 0.0351 - val_acc: 0.8950\n",
            "Epoch 131/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9733Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0279 - acc: 0.9732 - val_loss: 0.0341 - val_acc: 0.9000\n",
            "Epoch 132/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9713Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0275 - acc: 0.9715 - val_loss: 0.0353 - val_acc: 0.9000\n",
            "Epoch 133/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9752Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0269 - acc: 0.9745 - val_loss: 0.0340 - val_acc: 0.9050\n",
            "Epoch 134/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9755Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0271 - acc: 0.9756 - val_loss: 0.0350 - val_acc: 0.9050\n",
            "Epoch 135/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9752Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0266 - acc: 0.9755 - val_loss: 0.0341 - val_acc: 0.9150\n",
            "Epoch 136/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9690Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0269 - acc: 0.9696 - val_loss: 0.0340 - val_acc: 0.9100\n",
            "Epoch 137/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9722Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0264 - acc: 0.9726 - val_loss: 0.0331 - val_acc: 0.9250\n",
            "Epoch 138/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9729Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0262 - acc: 0.9733 - val_loss: 0.0324 - val_acc: 0.9100\n",
            "Epoch 139/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9740Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0265 - acc: 0.9741 - val_loss: 0.0339 - val_acc: 0.9050\n",
            "Epoch 140/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9777Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0254 - acc: 0.9778 - val_loss: 0.0333 - val_acc: 0.9050\n",
            "Epoch 141/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9762Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0258 - acc: 0.9763 - val_loss: 0.0346 - val_acc: 0.9150\n",
            "Epoch 142/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9752Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0257 - acc: 0.9748 - val_loss: 0.0323 - val_acc: 0.9100\n",
            "Epoch 143/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9755Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0254 - acc: 0.9751 - val_loss: 0.0324 - val_acc: 0.9200\n",
            "Epoch 144/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9777Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0251 - acc: 0.9775 - val_loss: 0.0319 - val_acc: 0.9200\n",
            "Epoch 145/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9778Epoch 1/200\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.0249 - acc: 0.9781 - val_loss: 0.0326 - val_acc: 0.9100\n",
            "Epoch 146/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9743Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0250 - acc: 0.9741 - val_loss: 0.0324 - val_acc: 0.9200\n",
            "Epoch 147/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9772Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0246 - acc: 0.9775 - val_loss: 0.0321 - val_acc: 0.9350\n",
            "Epoch 148/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9769Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0245 - acc: 0.9770 - val_loss: 0.0325 - val_acc: 0.9150\n",
            "Epoch 149/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9754Epoch 1/200\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.0244 - acc: 0.9752 - val_loss: 0.0316 - val_acc: 0.9250\n",
            "Epoch 150/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9767Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0242 - acc: 0.9767 - val_loss: 0.0319 - val_acc: 0.9250\n",
            "Epoch 151/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9788Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0243 - acc: 0.9786 - val_loss: 0.0317 - val_acc: 0.9250\n",
            "Epoch 152/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9780Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0235 - acc: 0.9778 - val_loss: 0.0324 - val_acc: 0.9200\n",
            "Epoch 153/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9793Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0240 - acc: 0.9793 - val_loss: 0.0318 - val_acc: 0.9150\n",
            "Epoch 154/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9802Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0236 - acc: 0.9805 - val_loss: 0.0313 - val_acc: 0.9100\n",
            "Epoch 155/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9795Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0236 - acc: 0.9797 - val_loss: 0.0305 - val_acc: 0.9250\n",
            "Epoch 156/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9808Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0229 - acc: 0.9808 - val_loss: 0.0305 - val_acc: 0.9150\n",
            "Epoch 157/200\n",
            "261/267 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9796Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0234 - acc: 0.9793 - val_loss: 0.0315 - val_acc: 0.9100\n",
            "Epoch 158/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9802Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0230 - acc: 0.9805 - val_loss: 0.0309 - val_acc: 0.9250\n",
            "Epoch 159/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9805Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0229 - acc: 0.9801 - val_loss: 0.0317 - val_acc: 0.9200\n",
            "Epoch 160/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9811Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0228 - acc: 0.9808 - val_loss: 0.0305 - val_acc: 0.9300\n",
            "Epoch 161/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9796Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0227 - acc: 0.9797 - val_loss: 0.0312 - val_acc: 0.9250\n",
            "Epoch 162/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9829Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0224 - acc: 0.9830 - val_loss: 0.0314 - val_acc: 0.9100\n",
            "Epoch 163/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9809Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0226 - acc: 0.9812 - val_loss: 0.0332 - val_acc: 0.9050\n",
            "Epoch 164/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9833Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0221 - acc: 0.9835 - val_loss: 0.0308 - val_acc: 0.9200\n",
            "Epoch 165/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9821Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0221 - acc: 0.9820 - val_loss: 0.0297 - val_acc: 0.9250\n",
            "Epoch 166/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9811Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0219 - acc: 0.9812 - val_loss: 0.0305 - val_acc: 0.9300\n",
            "Epoch 167/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9832Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0221 - acc: 0.9831 - val_loss: 0.0296 - val_acc: 0.9300\n",
            "Epoch 168/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9832Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0215 - acc: 0.9835 - val_loss: 0.0304 - val_acc: 0.9050\n",
            "Epoch 169/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9828Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0216 - acc: 0.9827 - val_loss: 0.0299 - val_acc: 0.9250\n",
            "Epoch 170/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9809Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0218 - acc: 0.9811 - val_loss: 0.0297 - val_acc: 0.9300\n",
            "Epoch 171/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9856Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0210 - acc: 0.9858 - val_loss: 0.0292 - val_acc: 0.9250\n",
            "Epoch 172/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9826Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0215 - acc: 0.9820 - val_loss: 0.0300 - val_acc: 0.9200\n",
            "Epoch 173/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9816Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0211 - acc: 0.9819 - val_loss: 0.0295 - val_acc: 0.9200\n",
            "Epoch 174/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9841Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0208 - acc: 0.9842 - val_loss: 0.0300 - val_acc: 0.9200\n",
            "Epoch 175/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9833Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0210 - acc: 0.9835 - val_loss: 0.0282 - val_acc: 0.9300\n",
            "Epoch 176/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9836Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0207 - acc: 0.9827 - val_loss: 0.0294 - val_acc: 0.9100\n",
            "Epoch 177/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9840Epoch 1/200\n",
            "267/267 [==============================] - 3s 11ms/step - loss: 0.0208 - acc: 0.9842 - val_loss: 0.0282 - val_acc: 0.9300\n",
            "Epoch 178/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9856Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0205 - acc: 0.9857 - val_loss: 0.0285 - val_acc: 0.9400\n",
            "Epoch 179/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9851Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0206 - acc: 0.9846 - val_loss: 0.0296 - val_acc: 0.9200\n",
            "Epoch 180/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9851Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0203 - acc: 0.9849 - val_loss: 0.0282 - val_acc: 0.9300\n",
            "Epoch 181/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9827Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0204 - acc: 0.9828 - val_loss: 0.0282 - val_acc: 0.9250\n",
            "Epoch 182/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9851Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0200 - acc: 0.9853 - val_loss: 0.0290 - val_acc: 0.9250\n",
            "Epoch 183/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9836Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0201 - acc: 0.9838 - val_loss: 0.0282 - val_acc: 0.9300\n",
            "Epoch 184/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9852Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0199 - acc: 0.9853 - val_loss: 0.0280 - val_acc: 0.9300\n",
            "Epoch 185/200\n",
            "261/267 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9874Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0197 - acc: 0.9872 - val_loss: 0.0290 - val_acc: 0.9200\n",
            "Epoch 186/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9815Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0201 - acc: 0.9816 - val_loss: 0.0295 - val_acc: 0.9250\n",
            "Epoch 187/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9849Epoch 1/200\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.0195 - acc: 0.9850 - val_loss: 0.0291 - val_acc: 0.9350\n",
            "Epoch 188/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9886Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0193 - acc: 0.9887 - val_loss: 0.0283 - val_acc: 0.9300\n",
            "Epoch 189/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9844Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0198 - acc: 0.9846 - val_loss: 0.0282 - val_acc: 0.9350\n",
            "Epoch 190/200\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9856Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0194 - acc: 0.9853 - val_loss: 0.0278 - val_acc: 0.9300\n",
            "Epoch 191/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9845Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0190 - acc: 0.9846 - val_loss: 0.0278 - val_acc: 0.9350\n",
            "Epoch 192/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9863Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0195 - acc: 0.9865 - val_loss: 0.0273 - val_acc: 0.9300\n",
            "Epoch 193/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9874Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0190 - acc: 0.9869 - val_loss: 0.0268 - val_acc: 0.9350\n",
            "Epoch 194/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9863Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0192 - acc: 0.9864 - val_loss: 0.0275 - val_acc: 0.9350\n",
            "Epoch 195/200\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9863Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0189 - acc: 0.9861 - val_loss: 0.0272 - val_acc: 0.9300\n",
            "Epoch 196/200\n",
            "263/267 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9870Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0188 - acc: 0.9872 - val_loss: 0.0273 - val_acc: 0.9350\n",
            "Epoch 197/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9874Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0189 - acc: 0.9869 - val_loss: 0.0267 - val_acc: 0.9600\n",
            "Epoch 198/200\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9873Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0188 - acc: 0.9876 - val_loss: 0.0270 - val_acc: 0.9300\n",
            "Epoch 199/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9876Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0185 - acc: 0.9876 - val_loss: 0.0268 - val_acc: 0.9300\n",
            "Epoch 200/200\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9876Epoch 1/200\n",
            "267/267 [==============================] - 3s 12ms/step - loss: 0.0187 - acc: 0.9876 - val_loss: 0.0274 - val_acc: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3EOWWJzfOXD",
        "colab_type": "text"
      },
      "source": [
        "# Lets see how we did\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d28dhbFpr98b",
        "outputId": "775468c8-14ee-4ad3-ccc4-a982ed0afb31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAHiCAYAAAA597/kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAXXIIiIiHvgfoLktUdOrvD0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpR7-axtgr7G",
        "colab_type": "text"
      },
      "source": [
        "As shown by the graph there is not much of an improvement after 150 *epochs*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B375_jqQhck_"
      },
      "source": [
        "# What were the failure cases\n",
        "here i am displaying a small sample of the cases where there was a mis classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mtJjG7UdhTmR",
        "outputId": "7dc36028-ee65-47c5-fb40-eb24a05d6085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "from keras.preprocessing import image\n",
        "for i in range(140):\n",
        "\n",
        "  img = image.load_img('/content/digits/4/crdigit'+str(600+i)+'.png', target_size=(30, 30))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict_classes(images, batch_size=1)\n",
        "\n",
        "  if (CLASS_NAMES[classes[0]] !='4'):\n",
        "        display.display(Image.open('/content/digits/4/crdigit'+str(600+i)+'.png'))\n",
        "        print(CLASS_NAMES[classes[0]])\n",
        "  \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeAQAAAAATS5MPAAAATklEQVR4nHWNsQ2AMBADD4uSHWCT\nMAbjsg1tyqA8mIKkg+Yky2d5MFwC+MYOODne6BV0A4oFOJNDpRfk2SEyaNqAONqM4uZR7dD4+9bx\nAJsHIAf1s/MkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=1 size=30x30 at 0x7FA7124C2390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFc9Ro4Ftl_L",
        "colab_type": "text"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfUlbmDpjayE",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model.save('clasifyDigits.h5') \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}